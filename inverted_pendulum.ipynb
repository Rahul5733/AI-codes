{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    \"\"\"Huber loss for Q Learning\n",
    "    References: https://en.wikipedia.org/wiki/Huber_loss\n",
    "                https://www.tensorflow.org/api_docs/python/tf/losses/huber_loss\n",
    "    \"\"\"\n",
    "\n",
    "    def _huber_loss(self, y_true, y_pred, clip_delta=1.0):\n",
    "        error = y_true - y_pred\n",
    "        cond  = K.abs(error) <= clip_delta\n",
    "\n",
    "        squared_loss = 0.5 * K.square(error)\n",
    "        quadratic_loss = 0.5 * K.square(clip_delta) + clip_delta * (K.abs(error) - clip_delta)\n",
    "\n",
    "        return K.mean(tf.where(cond, squared_loss, quadratic_loss))\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss=self._huber_loss,\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        # copy weights from model to target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                # a = self.model.predict(next_state)[0]\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "                # target[0][action] = reward + self.gamma * t[np.argmax(a)]\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action -> 1 [[-0.01399115 -0.02170298 -0.00243015 -0.02845564]]\n",
      "action -> 0 [[-0.01442521  0.17345374 -0.00299926 -0.32190432]]\n",
      "action -> 0 [[-0.01095613 -0.02162538 -0.00943735 -0.03016875]]\n",
      "action -> 0 [[-0.01138864 -0.21661073 -0.01004073  0.25952172]]\n",
      "action -> 0 [[-0.01572085 -0.41158791 -0.00485029  0.54902083]]\n",
      "action -> 1 [[-0.02395261 -0.60664139  0.00613013  0.84017163]]\n",
      "action -> 0 [[-0.03608544 -0.41160367  0.02293356  0.54942279]]\n",
      "action -> 1 [[-0.04431751 -0.60704013  0.03392201  0.84924227]]\n",
      "action -> 1 [[-0.05645831 -0.41239682  0.05090686  0.56741642]]\n",
      "action -> 1 [[-0.06470625 -0.21802453  0.06225519  0.29119584]]\n",
      "action -> 1 [[-0.06906674 -0.02384295  0.0680791   0.01877895]]\n",
      "action -> 1 [[-0.0695436   0.17023997  0.06845468 -0.25167125]]\n",
      "action -> 1 [[-0.0661388   0.36432102  0.06342126 -0.52200103]]\n",
      "action -> 1 [[-0.05885238  0.55849564  0.05298124 -0.79404403]]\n",
      "action -> 0 [[-0.04768247  0.75285187  0.03710036 -1.06960011]]\n",
      "action -> 0 [[-0.03262543  0.55725943  0.01570835 -0.76550833]]\n",
      "action -> 1 [[-2.14802418e-02  3.61924739e-01  3.98188057e-04 -4.67924383e-01]]\n",
      "action -> 1 [[-0.01424175  0.55704106 -0.0089603  -0.76048178]]\n",
      "action -> 0 [[-0.00310093  0.75228531 -0.02416994 -1.05597068]]\n",
      "action -> 1 [[ 0.01194478  0.55749189 -0.04528935 -0.77097116]]\n",
      "action -> 0 [[ 0.02309462  0.75320686 -0.06070877 -1.07755311]]\n",
      "action -> 1 [[ 0.03815876  0.55893702 -0.08225983 -0.8045226 ]]\n",
      "action -> 1 [[ 0.0493375   0.7550846  -0.09835029 -1.1219062 ]]\n",
      "action -> 0 [[ 0.06443919  0.95134892 -0.12078841 -1.44374841]]\n",
      "action -> 1 [[ 0.08346617  0.75790293 -0.14966338 -1.19111911]]\n",
      "action -> 0 [[ 0.09862422  0.95461298 -0.17348576 -1.5267227 ]]\n",
      "action -> 0 [[ 0.11771648  0.76195694 -0.20402021 -1.29282592]]\n",
      "episode: 0/50, score: 26, e: 1.0\n",
      "action -> 1 [[-0.00714948 -0.02441221 -0.0318771  -0.00120089]]\n",
      "action -> 1 [[-0.00763773  0.17115206 -0.03190112 -0.30376855]]\n",
      "action -> 0 [[-0.00421469  0.36671378 -0.03797649 -0.60633922]]\n",
      "action -> 0 [[ 0.00311959  0.17214285 -0.05010328 -0.32585566]]\n",
      "action -> 1 [[ 0.00656244 -0.02223126 -0.05662039 -0.04938457]]\n",
      "action -> 1 [[ 0.00611782  0.17365494 -0.05760808 -0.35938051]]\n",
      "action -> 0 [[ 0.00959092  0.36954648 -0.06479569 -0.66965778]]\n",
      "action -> 0 [[ 0.01698185  0.17538243 -0.07818885 -0.3980595 ]]\n",
      "action -> 0 [[ 0.0204895  -0.01854825 -0.08615004 -0.13101634]]\n",
      "action -> 1 [[ 0.02011853 -0.21233725 -0.08877036  0.13329234]]\n",
      "action -> 0 [[ 0.01587179 -0.01606329 -0.08610452 -0.18602358]]\n",
      "action -> 0 [[ 0.01555052 -0.2098545  -0.08982499  0.07830287]]\n",
      "action -> 1 [[ 0.01135343 -0.40358162 -0.08825893  0.34134897]]\n",
      "action -> 0 [[ 0.0032818  -0.20732206 -0.08143195  0.02219103]]\n",
      "action -> 1 [[-0.00086464 -0.4011875  -0.08098813  0.28811101]]\n",
      "action -> 0 [[-0.00888839 -0.20500963 -0.07522591 -0.02897575]]\n",
      "action -> 1 [[-0.01298859 -0.39897669 -0.07580542  0.23905643]]\n",
      "action -> 0 [[-0.02096812 -0.20285827 -0.0710243  -0.07654182]]\n",
      "action -> 0 [[-0.02502528 -0.39689396 -0.07255513  0.19291432]]\n",
      "action -> 1 [[-0.03296316 -0.59090704 -0.06869685  0.46185579]]\n",
      "action -> 1 [[-0.0447813  -0.39488484 -0.05945973  0.14833503]]\n",
      "action -> 0 [[-0.052679   -0.19896406 -0.05649303 -0.16249766]]\n",
      "action -> 0 [[-0.05665828 -0.39323367 -0.05974298  0.11184177]]\n",
      "action -> 0 [[-0.06452296 -0.58745093 -0.05750615  0.38509391]]\n",
      "action -> 1 [[-0.07627197 -0.78171133 -0.04980427  0.65910536]]\n",
      "action -> 1 [[-0.0919062  -0.5859329  -0.03662216  0.35116545]]\n",
      "action -> 1 [[-0.10362486 -0.3903098  -0.02959885  0.04716304]]\n",
      "action -> 1 [[-0.11143105 -0.1947762  -0.02865559 -0.25470968]]\n",
      "action -> 1 [[-0.11532658  0.00074293 -0.03374979 -0.55629157]]\n",
      "action -> 1 [[-0.11531172  0.19632206 -0.04487562 -0.85941374]]\n",
      "action -> 1 [[-0.11138528  0.39202558 -0.06206389 -1.1658625 ]]\n",
      "action -> 1 [[-0.10354477  0.58789795 -0.08538114 -1.47734045]]\n",
      "action -> 0 [[-0.09178681  0.78395255 -0.11492795 -1.79542264]]\n",
      "action -> 1 [[-0.07610776  0.59029006 -0.1508364  -1.54055976]]\n",
      "action -> 1 [[-0.06430196  0.78686985 -0.1816476  -1.87625936]]\n",
      "episode: 1/50, score: 34, e: 0.75\n",
      "action -> 1 [[-0.01280943 -0.04838862 -0.01325451  0.04977456]]\n",
      "action -> 1 [[-0.0137772   0.14692085 -0.01225901 -0.24706063]]\n",
      "action -> 1 [[-0.01083878  0.34221572 -0.01720023 -0.54358498]]\n",
      "action -> 1 [[-0.00399447  0.53757511 -0.02807193 -0.84163734]]\n",
      "action -> 0 [[ 0.00675703  0.73306878 -0.04490467 -1.14301437]]\n",
      "action -> 0 [[ 0.02141841  0.53856142 -0.06776496 -0.86474498]]\n",
      "action -> 1 [[ 0.03218964  0.34442408 -0.08505986 -0.59411499]]\n",
      "action -> 0 [[ 0.03907812  0.54062716 -0.09694216 -0.91233303]]\n",
      "action -> 1 [[ 0.04989066  0.34694098 -0.11518882 -0.65162423]]\n",
      "action -> 1 [[ 0.05682948  0.54346277 -0.12822131 -0.97824409]]\n",
      "action -> 1 [[ 0.06769874  0.74004893 -0.14778619 -1.3082965 ]]\n",
      "action -> 1 [[ 0.08249972  0.93670175 -0.17395212 -1.64335145]]\n",
      "action -> 1 [[ 0.10123375  1.1333813  -0.20681915 -1.98480287]]\n",
      "episode: 2/50, score: 12, e: 0.66\n",
      "action -> 0 [[-0.03476365 -0.01382118  0.04033596  0.01153478]]\n",
      "action -> 1 [[-0.03504007 -0.20949769  0.04056666  0.31666636]]\n",
      "action -> 1 [[-0.03923003 -0.01497633  0.04689999  0.0370477 ]]\n",
      "action -> 1 [[-0.03952955  0.17944278  0.04764094 -0.24047676]]\n",
      "action -> 0 [[-0.0359407   0.37385295  0.04283141 -0.51776   ]]\n",
      "action -> 0 [[-0.02846364  0.17815494  0.03247621 -0.21189362]]\n",
      "action -> 1 [[-0.02490054 -0.01741593  0.02823833  0.09085433]]\n",
      "action -> 1 [[-0.02524886  0.17729013  0.03005542 -0.19278735]]\n",
      "action -> 1 [[-0.02170306  0.37196953  0.02619967 -0.4758396 ]]\n",
      "action -> 0 [[-0.01426366  0.56671191  0.01668288 -0.76015111]]\n",
      "action -> 0 [[-0.00292943  0.37136413  0.00147986 -0.46226568]]\n",
      "action -> 1 [[ 0.00449786  0.1762213  -0.00776545 -0.16911667]]\n",
      "action -> 1 [[ 0.00802228  0.37145353 -0.01114779 -0.46423921]]\n",
      "action -> 1 [[ 0.01545135  0.56673123 -0.02043257 -0.76041494]]\n",
      "action -> 1 [[ 0.02678598  0.76212864 -0.03564087 -1.05945663]]\n",
      "action -> 1 [[ 0.04202855  0.95770411 -0.05683    -1.36310972]]\n",
      "action -> 0 [[ 0.06118263  1.15349015 -0.0840922  -1.6730137 ]]\n",
      "action -> 0 [[ 0.08425244  0.95943934 -0.11755247 -1.40766003]]\n",
      "action -> 0 [[ 0.10344122  0.76595578 -0.14570567 -1.15391852]]\n",
      "action -> 0 [[ 0.11876034  0.57300302 -0.16878404 -0.91024232]]\n",
      "action -> 0 [[ 0.1302204   0.38051762 -0.18698889 -0.67500435]]\n",
      "action -> 1 [[ 0.13783075  0.18841842 -0.20048898 -0.44653336]]\n",
      "action -> 1 [[ 0.14159912  0.38572792 -0.20941964 -0.79511891]]\n",
      "episode: 3/50, score: 22, e: 0.53\n",
      "action -> 1 [[-0.03842153  0.00623962 -0.02149597 -0.03219572]]\n",
      "action -> 1 [[-0.03829674  0.20166313 -0.02213989 -0.33158259]]\n",
      "action -> 1 [[-0.03426348  0.39709312 -0.02877154 -0.63116432]]\n",
      "action -> 1 [[-0.02632162  0.59260445 -0.04139483 -0.93276761]]\n",
      "action -> 1 [[-0.01446953  0.78825974 -0.06005018 -1.23816574]]\n",
      "action -> 0 [[ 1.29566832e-03  9.84099454e-01 -8.48134940e-02 -1.54903996e+00]]\n",
      "action -> 0 [[ 0.02097766  0.79009159 -0.11579429 -1.28397949]]\n",
      "action -> 1 [[ 0.03677949  0.59661863 -0.14147388 -1.02968099]]\n",
      "action -> 0 [[ 0.04871186  0.79331057 -0.1620675  -1.36322597]]\n",
      "action -> 1 [[ 0.06457807  0.60054711 -0.18933202 -1.12530932]]\n",
      "episode: 4/50, score: 9, e: 0.48\n",
      "action -> 1 [[-0.01847461 -0.00233466  0.04007044 -0.00826926]]\n",
      "action -> 1 [[-0.0185213   0.1921904   0.03990506 -0.28804507]]\n",
      "action -> 0 [[-0.01467749  0.38672124  0.03414416 -0.56788005]]\n",
      "action -> 0 [[-0.00694307  0.19113741  0.02278656 -0.26463887]]\n",
      "action -> 1 [[-0.00312032 -0.00430224  0.01749378  0.03514317]]\n",
      "action -> 1 [[-0.00320637  0.19056453  0.01819664 -0.25196936]]\n",
      "action -> 1 [[ 0.00060493  0.38542198  0.01315725 -0.53885763]]\n",
      "action -> 1 [[ 0.00831337  0.58035652  0.0023801  -0.827366  ]]\n",
      "action -> 0 [[ 0.0199205   0.77544584 -0.01416722 -1.11929941]]\n",
      "action -> 0 [[ 0.03542941  0.58051259 -0.03655321 -0.8310939 ]]\n",
      "action -> 1 [[ 0.04703966  0.38590879 -0.05317508 -0.55012744]]\n",
      "action -> 1 [[ 0.05475784  0.58173574 -0.06417763 -0.85907878]]\n",
      "action -> 1 [[ 0.06639255  0.77767042 -0.08135921 -1.17123103]]\n",
      "action -> 1 [[ 0.08194596  0.97375052 -0.10478383 -1.4882715 ]]\n",
      "action -> 0 [[ 0.10142097  1.16998116 -0.13454926 -1.81175313]]\n",
      "action -> 1 [[ 0.1248206   0.97659069 -0.17078432 -1.56372748]]\n",
      "action -> 0 [[ 0.14435241  1.1732934  -0.20205887 -1.90445591]]\n",
      "episode: 5/50, score: 16, e: 0.41\n",
      "action -> 1 [[ 0.03885492  0.02038104 -0.01395549 -0.02107869]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action -> 1 [[ 0.03926254  0.21570032 -0.01437706 -0.31813186]]\n",
      "action -> 0 [[ 0.04357655  0.41102406 -0.0207397  -0.61531389]]\n",
      "action -> 1 [[ 0.05179703  0.21619793 -0.03304598 -0.32923459]]\n",
      "action -> 1 [[ 0.05612099  0.41177435 -0.03963067 -0.63215279]]\n",
      "action -> 0 [[ 0.06435648  0.60742615 -0.05227373 -0.93704842]]\n",
      "action -> 0 [[ 0.076505    0.41304658 -0.07101469 -0.66123883]]\n",
      "action -> 0 [[ 0.08476593  0.21898089 -0.08423947 -0.39173477]]\n",
      "action -> 1 [[ 0.08914555  0.02514916 -0.09207417 -0.1267553 ]]\n",
      "action -> 0 [[ 0.08964853  0.22146126 -0.09460927 -0.44700772]]\n",
      "action -> 0 [[ 0.09407776  0.02779611 -0.10354943 -0.18558278]]\n",
      "action -> 1 [[ 0.09463368 -0.16570358 -0.10726108  0.0727229 ]]\n",
      "action -> 1 [[ 0.09131961  0.03077956 -0.10580662 -0.25178236]]\n",
      "action -> 0 [[ 0.0919352   0.22724077 -0.11084227 -0.57587531]]\n",
      "action -> 1 [[ 0.09648001  0.03383284 -0.12235978 -0.32006469]]\n",
      "action -> 0 [[ 0.09715667  0.2304656  -0.12876107 -0.6486927 ]]\n",
      "action -> 0 [[ 0.10176598  0.0373502  -0.14173492 -0.39916881]]\n",
      "action -> 0 [[ 0.10251299 -0.15550655 -0.1497183  -0.15431521]]\n",
      "action -> 0 [[ 0.09940286 -0.34820303 -0.15280461  0.08764308]]\n",
      "action -> 0 [[ 0.0924388  -0.54084207 -0.15105174  0.32848478]]\n",
      "action -> 0 [[ 0.08162195 -0.73352711 -0.14448205  0.56998076]]\n",
      "action -> 0 [[ 0.06695141 -0.92635883 -0.13308243  0.81388448]]\n",
      "action -> 0 [[ 0.04842424 -1.11943166 -0.11680474  1.06192203]]\n",
      "action -> 0 [[ 0.0260356  -1.31282968 -0.0955663   1.3157798 ]]\n",
      "action -> 0 [[-2.20991651e-04 -1.50662146e+00 -6.92507068e-02  1.57708732e+00]]\n",
      "action -> 0 [[-0.03035342 -1.70085328 -0.03770896  1.8473933 ]]\n",
      "action -> 0 [[-6.43704864e-02 -1.89554022e+00 -7.61094512e-04  2.12813230e+00]]\n",
      "action -> 1 [[-0.10228129 -2.09065461  0.04180155  2.42058004]]\n",
      "action -> 0 [[-0.14409438 -1.89591746  0.09021315  2.14101556]]\n",
      "action -> 0 [[-0.18201273 -2.09180696  0.13303346  2.46014165]]\n",
      "action -> 0 [[-0.22384887 -2.28777889  0.1822363   2.79049873]]\n",
      "episode: 6/50, score: 30, e: 0.31\n",
      "action -> 0 [[ 0.03604644 -0.01191755  0.01008859 -0.0412861 ]]\n",
      "action -> 1 [[ 0.03580809 -0.2071827   0.00926287  0.25456273]]\n",
      "action -> 0 [[ 0.03166443 -0.01219422  0.01435412 -0.0351842 ]]\n",
      "action -> 1 [[ 0.03142055 -0.20751904  0.01365044  0.26199282]]\n",
      "action -> 0 [[ 0.02727017 -0.01259458  0.0188903  -0.02635353]]\n",
      "action -> 0 [[ 0.02701827 -0.20798227  0.01836323  0.27222912]]\n",
      "action -> 1 [[ 0.02285863 -0.40336137  0.02380781  0.57064685]]\n",
      "action -> 0 [[ 0.0147914  -0.20858124  0.03522074  0.28555829]]\n",
      "action -> 0 [[ 0.01061978 -0.40418734  0.04093191  0.58913823]]\n",
      "action -> 1 [[ 0.00253603 -0.59985783  0.05271467  0.89442875]]\n",
      "action -> 1 [[-0.00946113 -0.40548884  0.07060325  0.6187712 ]]\n",
      "action -> 0 [[-0.0175709  -0.2114204   0.08297867  0.3491339 ]]\n",
      "action -> 0 [[-0.02179931 -0.40761846  0.08996135  0.66678612]]\n",
      "action -> 0 [[-0.02995168 -0.60386877  0.10329707  0.98638416]]\n",
      "action -> 0 [[-0.04202906 -0.800211    0.12302476  1.30964301]]\n",
      "action -> 0 [[-0.05803328 -0.99665776  0.14921762  1.63816414]]\n",
      "action -> 0 [[-0.07796643 -1.19318105  0.1819809   1.9733807 ]]\n",
      "episode: 7/50, score: 16, e: 0.26\n",
      "action -> 0 [[-0.0358256   0.01358201  0.02043581 -0.04756491]]\n",
      "action -> 0 [[-0.03555396 -0.18182692  0.01948451  0.25149499]]\n",
      "action -> 0 [[-0.0391905  -0.37722161  0.02451441  0.55025947]]\n",
      "action -> 1 [[-0.04673493 -0.57267916  0.0355196   0.85056422]]\n",
      "action -> 1 [[-0.05818851 -0.37805907  0.05253088  0.5692588 ]]\n",
      "action -> 1 [[-0.06574969 -0.18371171  0.06391606  0.29357686]]\n",
      "action -> 0 [[-0.06942393  0.0104435   0.06978759  0.02171726]]\n",
      "action -> 0 [[-0.06921506 -0.18560628  0.07022194  0.335577  ]]\n",
      "action -> 1 [[-0.07292718 -0.38165368  0.07693348  0.64955163]]\n",
      "action -> 1 [[-0.08056026 -0.18768292  0.08992451  0.38205226]]\n",
      "action -> 0 [[-0.08431391  0.00605479  0.09756556  0.11902208]]\n",
      "action -> 1 [[-0.08419282 -0.19031984  0.099946    0.44082195]]\n",
      "action -> 0 [[-0.08799922  0.00325616  0.10876244  0.18124222]]\n",
      "action -> 1 [[-0.08793409 -0.19324044  0.11238728  0.50615868]]\n",
      "action -> 1 [[-9.17989014e-02  1.33312279e-04  1.22510455e-01  2.50900333e-01]]\n",
      "action -> 1 [[-0.09179624  0.19331223  0.12752846 -0.00076817]]\n",
      "action -> 1 [[-0.08792999  0.38639647  0.1275131  -0.25065074]]\n",
      "action -> 1 [[-0.08020206  0.57948876  0.12250008 -0.50055032]]\n",
      "action -> 0 [[-0.06861229  0.7726902   0.11248908 -0.75225575]]\n",
      "action -> 0 [[-0.05315848  0.57621169  0.09744396 -0.42639858]]\n",
      "action -> 1 [[-0.04163425  0.37985433  0.08891599 -0.10465659]]\n",
      "action -> 1 [[-0.03403716  0.57359697  0.08682286 -0.36801563]]\n",
      "action -> 1 [[-0.02256522  0.76738484  0.07946255 -0.63210865]]\n",
      "action -> 0 [[-0.00721753  0.9613135   0.06682037 -0.89874633]]\n",
      "action -> 0 [[ 0.01200874  0.76535264  0.04884545 -0.58583044]]\n",
      "action -> 1 [[ 0.0273158   0.56958179  0.03712884 -0.27816955]]\n",
      "action -> 1 [[ 0.03870743  0.76415493  0.03156545 -0.55891475]]\n",
      "action -> 0 [[ 0.05399053  0.95881992  0.02038715 -0.84148807]]\n",
      "action -> 1 [[ 0.07316693  0.76342569  0.00355739 -0.54246423]]\n",
      "action -> 0 [[ 0.08843544  0.95849747 -0.00729189 -0.83402417]]\n",
      "action -> 1 [[ 0.10760539  0.7634759  -0.02397238 -0.54364339]]\n",
      "action -> 0 [[ 0.12287491  0.95892639 -0.03484525 -0.8437821 ]]\n",
      "action -> 1 [[ 0.14205344  0.76429685 -0.05172089 -0.56225744]]\n",
      "action -> 0 [[ 0.15733938  0.960105   -0.06296604 -0.87077606]]\n",
      "action -> 0 [[ 0.17654148  0.7658934  -0.08038156 -0.59853576]]\n",
      "action -> 0 [[ 0.19185934  0.5719827  -0.09235227 -0.3322156 ]]\n",
      "action -> 0 [[ 0.203299    0.3782883  -0.09899658 -0.07002512]]\n",
      "action -> 0 [[ 0.21086476  0.18471473 -0.10039709  0.1898561 ]]\n",
      "action -> 1 [[ 0.21455906 -0.00883829 -0.09659996  0.44925648]]\n",
      "action -> 1 [[ 0.21438229  0.18750781 -0.08761484  0.12775419]]\n",
      "action -> 1 [[ 0.21813245  0.38376852 -0.08505975 -0.19123349]]\n",
      "action -> 0 [[ 0.22580782  0.57999781 -0.08888442 -0.50949068]]\n",
      "action -> 0 [[ 0.23740778  0.38623312 -0.09907424 -0.24608864]]\n",
      "action -> 1 [[ 0.24513244  0.19265549 -0.10399601  0.01377369]]\n",
      "action -> 1 [[ 0.24898555  0.38910325 -0.10372053 -0.30982566]]\n",
      "action -> 0 [[ 0.25676761  0.58553829 -0.10991705 -0.6333339 ]]\n",
      "action -> 0 [[ 0.26847838  0.39210743 -0.12258373 -0.37718916]]\n",
      "action -> 0 [[ 0.27632053  0.19892033 -0.13012751 -0.12553244]]\n",
      "action -> 0 [[ 0.28029893  0.00587944 -0.13263816  0.12343115]]\n",
      "action -> 0 [[ 0.28041652 -0.1871175  -0.13016953  0.37150237]]\n",
      "action -> 0 [[ 0.27667417 -0.38017312 -0.12273949  0.62047404]]\n",
      "action -> 0 [[ 0.26907071 -0.5733865  -0.11033001  0.87211891]]\n",
      "action -> 0 [[ 0.25760298 -0.76684905 -0.09288763  1.12817706]]\n",
      "action -> 0 [[ 0.242266   -0.96063969 -0.07032409  1.39034017]]\n",
      "action -> 0 [[ 0.22305321 -1.15481878 -0.04251728  1.66023063]]\n",
      "action -> 0 [[ 0.19995683 -1.34942028 -0.00931267  1.93937276]]\n",
      "action -> 0 [[ 0.17296842 -1.54444162  0.02947478  2.2291542 ]]\n",
      "action -> 0 [[ 0.14207959 -1.73983075  0.07405787  2.53077492]]\n",
      "action -> 0 [[ 0.10728298 -1.93547021  0.12467337  2.84518286]]\n",
      "action -> 0 [[ 0.06857357 -2.13115821  0.18157702  3.17299564]]\n",
      "episode: 8/50, score: 59, e: 0.14\n",
      "action -> 1 [[ 0.00619465 -0.01502658  0.01599811 -0.01527062]]\n",
      "action -> 0 [[ 0.00589412  0.17986232  0.0156927  -0.30286333]]\n",
      "action -> 0 [[ 0.00949137 -0.01547972  0.00963543 -0.00527288]]\n",
      "action -> 0 [[ 0.00918177 -0.21073852  0.00952997  0.2904345 ]]\n",
      "action -> 1 [[ 0.004967   -0.40599506  0.01533866  0.58610777]]\n",
      "action -> 0 [[-0.0031529  -0.21109127  0.02706082  0.29829587]]\n",
      "action -> 0 [[-0.00737472 -0.4065883   0.03302673  0.59938896]]\n",
      "action -> 0 [[-0.01550649 -0.60215638  0.04501451  0.9022892 ]]\n",
      "action -> 0 [[-0.02754962 -0.7978583   0.0630603   1.20877451]]\n",
      "action -> 0 [[-0.04350678 -0.99373548  0.08723579  1.52053372]]\n",
      "action -> 1 [[-0.06338149 -1.18979676  0.11764646  1.83912213]]\n",
      "action -> 1 [[-0.08717743 -0.99615439  0.1544289   1.58517469]]\n",
      "action -> 0 [[-0.10710052 -0.80316914  0.1861324   1.34436359]]\n",
      "episode: 9/50, score: 12, e: 0.13\n",
      "action -> 0 [[ 0.00704373 -0.03109728 -0.04047517  0.00334178]]\n",
      "action -> 0 [[ 0.00642178 -0.22561609 -0.04040833  0.28298457]]\n",
      "action -> 0 [[ 0.00190946 -0.42013908 -0.03474864  0.56265406]]\n",
      "action -> 0 [[-0.00649332 -0.61475663 -0.02349556  0.84419012]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c5a7060f7eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# if e % 10 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#     agent.save(\"./save/cartpole-ddqn.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5f341d83987b>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mminibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.conda/envs/dl/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = gym.make('CartPole-v1')\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "    # agent.load(\"./save/cartpole-ddqn.h5\")\n",
    "    done = False\n",
    "    batch_size = 32\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        for time in range(500):\n",
    "            # env.render()\n",
    "            action = agent.act(state)\n",
    "            print(\"action ->\",action, state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            reward = reward if not done else -10\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                agent.update_target_model()\n",
    "                print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                      .format(e, EPISODES, time, agent.epsilon))\n",
    "                break\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "        # if e % 10 == 0:\n",
    "        #     agent.save(\"./save/cartpole-ddqn.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
